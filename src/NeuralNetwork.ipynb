{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc và xử lý dữ liệu từ file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = pd.read_csv('.\\\\mnist_train.csv')\n",
    "Test_data = pd.read_csv('.\\\\mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.610  \\\n",
       "0  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 785)\n",
      "(59999, 785)\n"
     ]
    }
   ],
   "source": [
    "print(Test_data.shape)\n",
    "print(Train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = np.array(Train_data)\n",
    "Test_data = np.array(Test_data)\n",
    "\n",
    "m_train, n_train = Train_data.shape\n",
    "m_test, n_test = Test_data.shape\n",
    "np.random.shuffle(Train_data)\n",
    "\n",
    "Train_data = Train_data[0: m_train].T\n",
    "Y_train = Train_data[0]\n",
    "X_train = Train_data[1: n_train]\n",
    "X_train = X_train / 255\n",
    "\n",
    "Test_data = Test_data[0: m_test].T\n",
    "Y_test = Test_data[0]\n",
    "X_test = Test_data[1: n_test]\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt các hàm tính toán cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def Softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def derivative_relu(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def foward_propagation(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = Softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def backpropagation(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2)\n",
    "\n",
    "    dZ1 = W2.T.dot(dZ2) * derivative_relu(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    #print(predictions)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt và thực nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, epochs, alpha):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        Z1, A1, Z2, A2 = foward_propagation(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backpropagation(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        predictions = get_predictions(A2)\n",
    "\n",
    "        print(\"Epochs {}: Accuracy: {}\".format(i + 1, get_accuracy(predictions, Y)))\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1: Accuracy: 0.09306821780363006\n",
      "Epochs 2: Accuracy: 0.10585176419606994\n",
      "Epochs 3: Accuracy: 0.12948549142485707\n",
      "Epochs 4: Accuracy: 0.15586926448774147\n",
      "Epochs 5: Accuracy: 0.18225303755062586\n",
      "Epochs 6: Accuracy: 0.20583676394606576\n",
      "Epochs 7: Accuracy: 0.22885381423023718\n",
      "Epochs 8: Accuracy: 0.24753745895764928\n",
      "Epochs 9: Accuracy: 0.2628877147952466\n",
      "Epochs 10: Accuracy: 0.27612126868781145\n",
      "Epochs 11: Accuracy: 0.28908815146919115\n",
      "Epochs 12: Accuracy: 0.3060884348072468\n",
      "Epochs 13: Accuracy: 0.3326722112035201\n",
      "Epochs 14: Accuracy: 0.3473391223187053\n",
      "Epochs 15: Accuracy: 0.3570226170436174\n",
      "Epochs 16: Accuracy: 0.36607276787946463\n",
      "Epochs 17: Accuracy: 0.37495624927082116\n",
      "Epochs 18: Accuracy: 0.3832897214953583\n",
      "Epochs 19: Accuracy: 0.3916398606643444\n",
      "Epochs 20: Accuracy: 0.4001400023333722\n",
      "Epochs 21: Accuracy: 0.4074401240020667\n",
      "Epochs 22: Accuracy: 0.41527358789313157\n",
      "Epochs 23: Accuracy: 0.42215703595059917\n",
      "Epochs 24: Accuracy: 0.4303905065084418\n",
      "Epochs 25: Accuracy: 0.4378072967882798\n",
      "Epochs 26: Accuracy: 0.4459740995683261\n",
      "Epochs 27: Accuracy: 0.4527075451257521\n",
      "Epochs 28: Accuracy: 0.46015766929448826\n",
      "Epochs 29: Accuracy: 0.4676077934632244\n",
      "Epochs 30: Accuracy: 0.47497458290971517\n",
      "Epochs 31: Accuracy: 0.48265804430073833\n",
      "Epochs 32: Accuracy: 0.4904915081918032\n",
      "Epochs 33: Accuracy: 0.49852497541625695\n",
      "Epochs 34: Accuracy: 0.5064584409740163\n",
      "Epochs 35: Accuracy: 0.514041900698345\n",
      "Epochs 36: Accuracy: 0.5217253620893681\n",
      "Epochs 37: Accuracy: 0.5295421590359839\n",
      "Epochs 38: Accuracy: 0.5380423007050118\n",
      "Epochs 39: Accuracy: 0.5464591076517942\n",
      "Epochs 40: Accuracy: 0.5543092384873082\n",
      "Epochs 41: Accuracy: 0.5623260387673128\n",
      "Epochs 42: Accuracy: 0.569792829880498\n",
      "Epochs 43: Accuracy: 0.577426290438174\n",
      "Epochs 44: Accuracy: 0.5848764146069101\n",
      "Epochs 45: Accuracy: 0.5918931982199703\n",
      "Epochs 46: Accuracy: 0.5992766546109102\n",
      "Epochs 47: Accuracy: 0.6057767629460491\n",
      "Epochs 48: Accuracy: 0.6128102135035584\n",
      "Epochs 49: Accuracy: 0.6197769962832714\n",
      "Epochs 50: Accuracy: 0.6269104485074751\n",
      "Epochs 51: Accuracy: 0.6333772229537159\n",
      "Epochs 52: Accuracy: 0.6399439990666511\n",
      "Epochs 53: Accuracy: 0.6457274287904798\n",
      "Epochs 54: Accuracy: 0.6516275271254521\n",
      "Epochs 55: Accuracy: 0.6573609560159336\n",
      "Epochs 56: Accuracy: 0.6631277187953133\n",
      "Epochs 57: Accuracy: 0.6685778096301606\n",
      "Epochs 58: Accuracy: 0.6735778929648828\n",
      "Epochs 59: Accuracy: 0.6787613126885448\n",
      "Epochs 60: Accuracy: 0.6833613893564893\n",
      "Epochs 61: Accuracy: 0.6877281288021467\n",
      "Epochs 62: Accuracy: 0.6917781963032718\n",
      "Epochs 63: Accuracy: 0.6955615926932116\n",
      "Epochs 64: Accuracy: 0.6992283204720079\n",
      "Epochs 65: Accuracy: 0.7027450457507625\n",
      "Epochs 66: Accuracy: 0.7065951099184986\n",
      "Epochs 67: Accuracy: 0.7102451707528459\n",
      "Epochs 68: Accuracy: 0.7137618960316006\n",
      "Epochs 69: Accuracy: 0.7167119451990867\n",
      "Epochs 70: Accuracy: 0.7200953349222488\n",
      "Epochs 71: Accuracy: 0.7230120502008367\n",
      "Epochs 72: Accuracy: 0.7261954365906098\n",
      "Epochs 73: Accuracy: 0.729378822980383\n",
      "Epochs 74: Accuracy: 0.7321788696478274\n",
      "Epochs 75: Accuracy: 0.7347122452040867\n",
      "Epochs 76: Accuracy: 0.7368289471491192\n",
      "Epochs 77: Accuracy: 0.7394456574276238\n",
      "Epochs 78: Accuracy: 0.7421123685394757\n",
      "Epochs 79: Accuracy: 0.7442957382623043\n",
      "Epochs 80: Accuracy: 0.7465124418740312\n",
      "Epochs 81: Accuracy: 0.7485124752079201\n",
      "Epochs 82: Accuracy: 0.7505458424307072\n",
      "Epochs 83: Accuracy: 0.752529208820147\n",
      "Epochs 84: Accuracy: 0.7546625777096285\n",
      "Epochs 85: Accuracy: 0.7569126152102535\n",
      "Epochs 86: Accuracy: 0.758579309655161\n",
      "Epochs 87: Accuracy: 0.7605960099334989\n",
      "Epochs 88: Accuracy: 0.7622293704895081\n",
      "Epochs 89: Accuracy: 0.7638460641010684\n",
      "Epochs 90: Accuracy: 0.7656294271571192\n",
      "Epochs 91: Accuracy: 0.7674127902131702\n",
      "Epochs 92: Accuracy: 0.7691294854914249\n",
      "Epochs 93: Accuracy: 0.7708795146585776\n",
      "Epochs 94: Accuracy: 0.7724295404923416\n",
      "Epochs 95: Accuracy: 0.7742462374372906\n",
      "Epochs 96: Accuracy: 0.7757462624377073\n",
      "Epochs 97: Accuracy: 0.7772296204936749\n",
      "Epochs 98: Accuracy: 0.7786796446607444\n",
      "Epochs 99: Accuracy: 0.7800130002166703\n",
      "Epochs 100: Accuracy: 0.7811630193836564\n",
      "Epochs 101: Accuracy: 0.7828797146619111\n",
      "Epochs 102: Accuracy: 0.7841130685511425\n",
      "Epochs 103: Accuracy: 0.7856797613293555\n",
      "Epochs 104: Accuracy: 0.786913115218587\n",
      "Epochs 105: Accuracy: 0.7881964699411657\n",
      "Epochs 106: Accuracy: 0.7893631560526009\n",
      "Epochs 107: Accuracy: 0.7906465107751796\n",
      "Epochs 108: Accuracy: 0.7917131952199203\n",
      "Epochs 109: Accuracy: 0.7929465491091519\n",
      "Epochs 110: Accuracy: 0.7934965582759713\n",
      "Epochs 111: Accuracy: 0.7948965816096935\n",
      "Epochs 112: Accuracy: 0.7958465974432907\n",
      "Epochs 113: Accuracy: 0.7968299471657861\n",
      "Epochs 114: Accuracy: 0.7979466324438741\n",
      "Epochs 115: Accuracy: 0.7987133118885315\n",
      "Epochs 116: Accuracy: 0.7996466607776797\n",
      "Epochs 117: Accuracy: 0.8008133468891148\n",
      "Epochs 118: Accuracy: 0.8007800130002166\n",
      "Epochs 119: Accuracy: 0.8023133718895314\n",
      "Epochs 120: Accuracy: 0.8015633593893231\n",
      "Epochs 121: Accuracy: 0.8011133518891982\n",
      "Epochs 122: Accuracy: 0.7991466524442074\n",
      "Epochs 123: Accuracy: 0.7938298971649528\n",
      "Epochs 124: Accuracy: 0.7824630410506842\n",
      "Epochs 125: Accuracy: 0.7711961866031101\n",
      "Epochs 126: Accuracy: 0.7571626193769896\n",
      "Epochs 127: Accuracy: 0.7582793046550775\n",
      "Epochs 128: Accuracy: 0.7524625410423507\n",
      "Epochs 129: Accuracy: 0.7632127202120035\n",
      "Epochs 130: Accuracy: 0.7559125985433091\n",
      "Epochs 131: Accuracy: 0.7652794213236888\n",
      "Epochs 132: Accuracy: 0.7572126202103369\n",
      "Epochs 133: Accuracy: 0.7685794763246054\n",
      "Epochs 134: Accuracy: 0.7637293954899248\n",
      "Epochs 135: Accuracy: 0.7746795779929665\n",
      "Epochs 136: Accuracy: 0.77209620160336\n",
      "Epochs 137: Accuracy: 0.7823463724395406\n",
      "Epochs 138: Accuracy: 0.7821463691061518\n",
      "Epochs 139: Accuracy: 0.7902465041084018\n",
      "Epochs 140: Accuracy: 0.7906131768862814\n",
      "Epochs 141: Accuracy: 0.7972799546659111\n",
      "Epochs 142: Accuracy: 0.7971966199436658\n",
      "Epochs 143: Accuracy: 0.8025300421673695\n",
      "Epochs 144: Accuracy: 0.802646710778513\n",
      "Epochs 145: Accuracy: 0.8068134468907815\n",
      "Epochs 146: Accuracy: 0.8065134418906982\n",
      "Epochs 147: Accuracy: 0.8101135018916982\n",
      "Epochs 148: Accuracy: 0.8103468391139852\n",
      "Epochs 149: Accuracy: 0.8130135502258371\n",
      "Epochs 150: Accuracy: 0.8128135468924482\n",
      "Epochs 151: Accuracy: 0.8151302521708695\n",
      "Epochs 152: Accuracy: 0.815246920782013\n",
      "Epochs 153: Accuracy: 0.8169302821713695\n",
      "Epochs 154: Accuracy: 0.8169636160602677\n",
      "Epochs 155: Accuracy: 0.8187803130052168\n",
      "Epochs 156: Accuracy: 0.8185803096718278\n",
      "Epochs 157: Accuracy: 0.8198636643944066\n",
      "Epochs 158: Accuracy: 0.819963666061101\n",
      "Epochs 159: Accuracy: 0.8211970199503325\n",
      "Epochs 160: Accuracy: 0.8211136852280871\n",
      "Epochs 161: Accuracy: 0.8220637010616844\n",
      "Epochs 162: Accuracy: 0.8223137052284205\n",
      "Epochs 163: Accuracy: 0.8229970499508326\n",
      "Epochs 164: Accuracy: 0.8233970566176103\n",
      "Epochs 165: Accuracy: 0.8238637310621844\n",
      "Epochs 166: Accuracy: 0.8242637377289621\n",
      "Epochs 167: Accuracy: 0.8247970799513326\n",
      "Epochs 168: Accuracy: 0.8250137502291705\n",
      "Epochs 169: Accuracy: 0.8258470974516242\n",
      "Epochs 170: Accuracy: 0.8256470941182353\n",
      "Epochs 171: Accuracy: 0.8264304405073418\n",
      "Epochs 172: Accuracy: 0.8264137735628927\n",
      "Epochs 173: Accuracy: 0.8273304555075918\n",
      "Epochs 174: Accuracy: 0.8269804496741613\n",
      "Epochs 175: Accuracy: 0.8282304705078418\n",
      "Epochs 176: Accuracy: 0.8276971282854714\n",
      "Epochs 177: Accuracy: 0.8286804780079668\n",
      "Epochs 178: Accuracy: 0.8284138068967816\n",
      "Epochs 179: Accuracy: 0.8292304871747862\n",
      "Epochs 180: Accuracy: 0.8290138168969483\n",
      "Epochs 181: Accuracy: 0.8299304988416474\n",
      "Epochs 182: Accuracy: 0.8297471624527075\n",
      "Epochs 183: Accuracy: 0.8309305155085918\n",
      "Epochs 184: Accuracy: 0.8307138452307539\n",
      "Epochs 185: Accuracy: 0.8317805296754945\n",
      "Epochs 186: Accuracy: 0.8313971899531659\n",
      "Epochs 187: Accuracy: 0.832330538842314\n",
      "Epochs 188: Accuracy: 0.8321472024533743\n",
      "Epochs 189: Accuracy: 0.8331638860647678\n",
      "Epochs 190: Accuracy: 0.8331305521758696\n",
      "Epochs 191: Accuracy: 0.8339805663427724\n",
      "Epochs 192: Accuracy: 0.8340805680094668\n",
      "Epochs 193: Accuracy: 0.8351639193986566\n",
      "Epochs 194: Accuracy: 0.8350305838430641\n",
      "Epochs 195: Accuracy: 0.836130602176703\n",
      "Epochs 196: Accuracy: 0.8359639327322123\n",
      "Epochs 197: Accuracy: 0.8369972832880548\n",
      "Epochs 198: Accuracy: 0.8372139535658928\n",
      "Epochs 199: Accuracy: 0.8376639610660178\n",
      "Epochs 200: Accuracy: 0.8381473024550409\n",
      "Epochs 201: Accuracy: 0.8385473091218187\n",
      "Epochs 202: Accuracy: 0.838847314121902\n",
      "Epochs 203: Accuracy: 0.8395473257887631\n",
      "Epochs 204: Accuracy: 0.8397973299554993\n",
      "Epochs 205: Accuracy: 0.8402640044000733\n",
      "Epochs 206: Accuracy: 0.8406973449557492\n",
      "Epochs 207: Accuracy: 0.8409640160669345\n",
      "Epochs 208: Accuracy: 0.841547359122652\n",
      "Epochs 209: Accuracy: 0.8417973632893881\n",
      "Epochs 210: Accuracy: 0.8423307055117585\n",
      "Epochs 211: Accuracy: 0.8423640394006566\n",
      "Epochs 212: Accuracy: 0.843097384956416\n",
      "Epochs 213: Accuracy: 0.8429973832897215\n",
      "Epochs 214: Accuracy: 0.8436140602343373\n",
      "Epochs 215: Accuracy: 0.8437473957899299\n",
      "Epochs 216: Accuracy: 0.8443307388456475\n",
      "Epochs 217: Accuracy: 0.8443807396789946\n",
      "Epochs 218: Accuracy: 0.8450640844014067\n",
      "Epochs 219: Accuracy: 0.845130752179203\n",
      "Epochs 220: Accuracy: 0.8456640944015733\n",
      "Epochs 221: Accuracy: 0.8459807663461058\n",
      "Epochs 222: Accuracy: 0.8460641010683512\n",
      "Epochs 223: Accuracy: 0.8464641077351289\n",
      "Epochs 224: Accuracy: 0.8465474424573743\n",
      "Epochs 225: Accuracy: 0.8470141169019484\n",
      "Epochs 226: Accuracy: 0.8472141202353373\n",
      "Epochs 227: Accuracy: 0.8474974582909716\n",
      "Epochs 228: Accuracy: 0.8476307938465641\n",
      "Epochs 229: Accuracy: 0.8481141352355872\n",
      "Epochs 230: Accuracy: 0.8481808030133836\n",
      "Epochs 231: Accuracy: 0.8486308105135085\n",
      "Epochs 232: Accuracy: 0.848730812180203\n",
      "Epochs 233: Accuracy: 0.849164152735879\n",
      "Epochs 234: Accuracy: 0.8490308171802864\n",
      "Epochs 235: Accuracy: 0.8496974949582493\n",
      "Epochs 236: Accuracy: 0.8494974916248604\n",
      "Epochs 237: Accuracy: 0.850080834680578\n",
      "Epochs 238: Accuracy: 0.849647494124902\n",
      "Epochs 239: Accuracy: 0.8505641760696011\n",
      "Epochs 240: Accuracy: 0.8499808330138836\n",
      "Epochs 241: Accuracy: 0.8511141852364206\n",
      "Epochs 242: Accuracy: 0.8503141719028651\n",
      "Epochs 243: Accuracy: 0.8515975266254437\n",
      "Epochs 244: Accuracy: 0.8507141785696428\n",
      "Epochs 245: Accuracy: 0.8520975349589159\n",
      "Epochs 246: Accuracy: 0.8511308521808697\n",
      "Epochs 247: Accuracy: 0.8525642094034901\n",
      "Epochs 248: Accuracy: 0.8515641927365456\n",
      "Epochs 249: Accuracy: 0.8530975516258604\n",
      "Epochs 250: Accuracy: 0.8520808680144669\n",
      "Epochs 251: Accuracy: 0.853447557459291\n",
      "Epochs 252: Accuracy: 0.8526975449590827\n",
      "Epochs 253: Accuracy: 0.8537975632927215\n",
      "Epochs 254: Accuracy: 0.8530475507925132\n",
      "Epochs 255: Accuracy: 0.8542142369039484\n",
      "Epochs 256: Accuracy: 0.85346422440374\n",
      "Epochs 257: Accuracy: 0.8547642460707678\n",
      "Epochs 258: Accuracy: 0.8539142319038651\n",
      "Epochs 259: Accuracy: 0.8552975882931382\n",
      "Epochs 260: Accuracy: 0.8543642394039901\n",
      "Epochs 261: Accuracy: 0.8558975982933049\n",
      "Epochs 262: Accuracy: 0.8548475807930133\n",
      "Epochs 263: Accuracy: 0.856364272737879\n",
      "Epochs 264: Accuracy: 0.8553142552375873\n",
      "Epochs 265: Accuracy: 0.8569642827380456\n",
      "Epochs 266: Accuracy: 0.8556309271821197\n",
      "Epochs 267: Accuracy: 0.8572476207936799\n",
      "Epochs 268: Accuracy: 0.8562142702378372\n",
      "Epochs 269: Accuracy: 0.857497624960416\n",
      "Epochs 270: Accuracy: 0.8567309455157586\n",
      "Epochs 271: Accuracy: 0.8579142985716428\n",
      "Epochs 272: Accuracy: 0.8570976182936382\n",
      "Epochs 273: Accuracy: 0.8581976366272771\n",
      "Epochs 274: Accuracy: 0.8575642927382123\n",
      "Epochs 275: Accuracy: 0.858630977182953\n",
      "Epochs 276: Accuracy: 0.8580309671827864\n",
      "Epochs 277: Accuracy: 0.8589476491274854\n",
      "Epochs 278: Accuracy: 0.8582643044050734\n",
      "Epochs 279: Accuracy: 0.8594309905165086\n",
      "Epochs 280: Accuracy: 0.8584476407940133\n",
      "Epochs 281: Accuracy: 0.8597643294054901\n",
      "Epochs 282: Accuracy: 0.8588643144052401\n",
      "Epochs 283: Accuracy: 0.8603310055167586\n",
      "Epochs 284: Accuracy: 0.859064317738629\n",
      "Epochs 285: Accuracy: 0.8606143435723929\n",
      "Epochs 286: Accuracy: 0.8595143252387539\n",
      "Epochs 287: Accuracy: 0.8610310171836197\n",
      "Epochs 288: Accuracy: 0.8598643310721845\n",
      "Epochs 289: Accuracy: 0.8615476924615411\n",
      "Epochs 290: Accuracy: 0.8601143352389207\n",
      "Epochs 291: Accuracy: 0.8620143669061151\n",
      "Epochs 292: Accuracy: 0.8605143419056984\n",
      "Epochs 293: Accuracy: 0.8622477041284021\n",
      "Epochs 294: Accuracy: 0.8608310138502309\n",
      "Epochs 295: Accuracy: 0.8625810430173836\n",
      "Epochs 296: Accuracy: 0.8611643527392123\n",
      "Epochs 297: Accuracy: 0.8629143819063652\n",
      "Epochs 298: Accuracy: 0.8614310238503975\n",
      "Epochs 299: Accuracy: 0.8632810546842448\n",
      "Epochs 300: Accuracy: 0.861764362739379\n",
      "Epochs 301: Accuracy: 0.8634977249620827\n",
      "Epochs 302: Accuracy: 0.8620810346839114\n",
      "Epochs 303: Accuracy: 0.8637643960732679\n",
      "Epochs 304: Accuracy: 0.8622643710728513\n",
      "Epochs 305: Accuracy: 0.8641144019066984\n",
      "Epochs 306: Accuracy: 0.8624810413506891\n",
      "Epochs 307: Accuracy: 0.8644310738512309\n",
      "Epochs 308: Accuracy: 0.8628143802396706\n",
      "Epochs 309: Accuracy: 0.864681078017967\n",
      "Epochs 310: Accuracy: 0.8632643877397956\n",
      "Epochs 311: Accuracy: 0.8649810830180503\n",
      "Epochs 312: Accuracy: 0.8635143919065318\n",
      "Epochs 313: Accuracy: 0.8652144202403373\n",
      "Epochs 314: Accuracy: 0.8639143985733095\n",
      "Epochs 315: Accuracy: 0.8655977599626661\n",
      "Epochs 316: Accuracy: 0.8642810713511891\n",
      "Epochs 317: Accuracy: 0.8658810980183003\n",
      "Epochs 318: Accuracy: 0.8646310771846197\n",
      "Epochs 319: Accuracy: 0.8661311021850364\n",
      "Epochs 320: Accuracy: 0.8648810813513559\n",
      "Epochs 321: Accuracy: 0.8664311071851197\n",
      "Epochs 322: Accuracy: 0.8652644210736845\n",
      "Epochs 323: Accuracy: 0.8668144469074485\n",
      "Epochs 324: Accuracy: 0.8655477591293188\n",
      "Epochs 325: Accuracy: 0.8672311205186753\n",
      "Epochs 326: Accuracy: 0.8658310971849531\n",
      "Epochs 327: Accuracy: 0.8675144585743095\n",
      "Epochs 328: Accuracy: 0.8660811013516891\n",
      "Epochs 329: Accuracy: 0.8677311288521475\n",
      "Epochs 330: Accuracy: 0.8664144402406707\n",
      "Epochs 331: Accuracy: 0.8679144652410874\n",
      "Epochs 332: Accuracy: 0.866714445240754\n",
      "Epochs 333: Accuracy: 0.8681978032967216\n",
      "Epochs 334: Accuracy: 0.8670477841297355\n",
      "Epochs 335: Accuracy: 0.8683144719078651\n",
      "Epochs 336: Accuracy: 0.8673477891298188\n",
      "Epochs 337: Accuracy: 0.8686478107968466\n",
      "Epochs 338: Accuracy: 0.8677311288521475\n",
      "Epochs 339: Accuracy: 0.8688978149635828\n",
      "Epochs 340: Accuracy: 0.8680144669077818\n",
      "Epochs 341: Accuracy: 0.8691978199636661\n",
      "Epochs 342: Accuracy: 0.8681978032967216\n",
      "Epochs 343: Accuracy: 0.8694311571859531\n",
      "Epochs 344: Accuracy: 0.8683811396856614\n",
      "Epochs 345: Accuracy: 0.8696811613526892\n",
      "Epochs 346: Accuracy: 0.8688144802413373\n",
      "Epochs 347: Accuracy: 0.8699144985749763\n",
      "Epochs 348: Accuracy: 0.8690644844080735\n",
      "Epochs 349: Accuracy: 0.870097834963916\n",
      "Epochs 350: Accuracy: 0.8693311555192587\n",
      "Epochs 351: Accuracy: 0.8703645060751013\n",
      "Epochs 352: Accuracy: 0.8695311588526475\n",
      "Epochs 353: Accuracy: 0.8706145102418373\n",
      "Epochs 354: Accuracy: 0.8697311621860364\n",
      "Epochs 355: Accuracy: 0.8708645144085735\n",
      "Epochs 356: Accuracy: 0.8700145002416707\n",
      "Epochs 357: Accuracy: 0.8710311838530642\n",
      "Epochs 358: Accuracy: 0.8703645060751013\n",
      "Epochs 359: Accuracy: 0.8712311871864531\n",
      "Epochs 360: Accuracy: 0.8707145119085318\n",
      "Epochs 361: Accuracy: 0.8713978566309438\n",
      "Epochs 362: Accuracy: 0.8709311821863698\n",
      "Epochs 363: Accuracy: 0.8717811963532726\n",
      "Epochs 364: Accuracy: 0.8710645177419624\n",
      "Epochs 365: Accuracy: 0.8719811996866614\n",
      "Epochs 366: Accuracy: 0.8712978549642494\n",
      "Epochs 367: Accuracy: 0.8722145369089485\n",
      "Epochs 368: Accuracy: 0.8715311921865364\n",
      "Epochs 369: Accuracy: 0.8724645410756846\n",
      "Epochs 370: Accuracy: 0.8717978632977216\n",
      "Epochs 371: Accuracy: 0.8726645444090735\n",
      "Epochs 372: Accuracy: 0.8719978666311106\n",
      "Epochs 373: Accuracy: 0.8729312155202587\n",
      "Epochs 374: Accuracy: 0.8722478707978466\n",
      "Epochs 375: Accuracy: 0.873231220520342\n",
      "Epochs 376: Accuracy: 0.8723812063534392\n",
      "Epochs 377: Accuracy: 0.8734312238537308\n",
      "Epochs 378: Accuracy: 0.8726978782979716\n",
      "Epochs 379: Accuracy: 0.8736478941315688\n",
      "Epochs 380: Accuracy: 0.8728812146869115\n",
      "Epochs 381: Accuracy: 0.8739478991316522\n",
      "Epochs 382: Accuracy: 0.8731978866314438\n",
      "Epochs 383: Accuracy: 0.8740645677427957\n",
      "Epochs 384: Accuracy: 0.8733978899648327\n",
      "Epochs 385: Accuracy: 0.8743979066317772\n",
      "Epochs 386: Accuracy: 0.8735478924648744\n",
      "Epochs 387: Accuracy: 0.8746312438540642\n",
      "Epochs 388: Accuracy: 0.8737812296871614\n",
      "Epochs 389: Accuracy: 0.8747645794096568\n",
      "Epochs 390: Accuracy: 0.8740979016316939\n",
      "Epochs 391: Accuracy: 0.8749312488541475\n",
      "Epochs 392: Accuracy: 0.8743145719095319\n",
      "Epochs 393: Accuracy: 0.8751312521875365\n",
      "Epochs 394: Accuracy: 0.8745312421873698\n",
      "Epochs 395: Accuracy: 0.87524792079868\n",
      "Epochs 396: Accuracy: 0.8746812446874115\n",
      "Epochs 397: Accuracy: 0.8753979232987217\n",
      "Epochs 398: Accuracy: 0.8749479157985967\n",
      "Epochs 399: Accuracy: 0.875481258020967\n",
      "Epochs 400: Accuracy: 0.8751479191319855\n",
      "Epochs 401: Accuracy: 0.8756812613543559\n",
      "Epochs 402: Accuracy: 0.8753645894098235\n",
      "Epochs 403: Accuracy: 0.875931265521092\n",
      "Epochs 404: Accuracy: 0.875697928298805\n",
      "Epochs 405: Accuracy: 0.8761146019100319\n",
      "Epochs 406: Accuracy: 0.8758979316321939\n",
      "Epochs 407: Accuracy: 0.8762979382989716\n",
      "Epochs 408: Accuracy: 0.8760146002433374\n",
      "Epochs 409: Accuracy: 0.8766312771879531\n",
      "Epochs 410: Accuracy: 0.8763146052434208\n",
      "Epochs 411: Accuracy: 0.8768312805213421\n",
      "Epochs 412: Accuracy: 0.8763979399656661\n",
      "Epochs 413: Accuracy: 0.8769812830213837\n",
      "Epochs 414: Accuracy: 0.8766812780213004\n",
      "Epochs 415: Accuracy: 0.8771479524658744\n",
      "Epochs 416: Accuracy: 0.8767646127435458\n",
      "Epochs 417: Accuracy: 0.8773812896881614\n",
      "Epochs 418: Accuracy: 0.8770646177436291\n",
      "Epochs 419: Accuracy: 0.8775479591326522\n",
      "Epochs 420: Accuracy: 0.8772146202436707\n",
      "Epochs 421: Accuracy: 0.8777479624660411\n",
      "Epochs 422: Accuracy: 0.8774312905215087\n",
      "Epochs 423: Accuracy: 0.8777812963549393\n",
      "Epochs 424: Accuracy: 0.8776146269104486\n",
      "Epochs 425: Accuracy: 0.8780313005216753\n",
      "Epochs 426: Accuracy: 0.877714628577143\n",
      "Epochs 427: Accuracy: 0.8781979699661661\n",
      "Epochs 428: Accuracy: 0.8779146319105319\n",
      "Epochs 429: Accuracy: 0.878397973299555\n",
      "Epochs 430: Accuracy: 0.8780813013550226\n",
      "Epochs 431: Accuracy: 0.8785479757995966\n",
      "Epochs 432: Accuracy: 0.8782479707995133\n",
      "Epochs 433: Accuracy: 0.8786646444107402\n",
      "Epochs 434: Accuracy: 0.8782813046884115\n",
      "Epochs 435: Accuracy: 0.8788146469107818\n",
      "Epochs 436: Accuracy: 0.8784479741329022\n",
      "Epochs 437: Accuracy: 0.8790479841330688\n",
      "Epochs 438: Accuracy: 0.8785979766329439\n",
      "Epochs 439: Accuracy: 0.8791479857997633\n",
      "Epochs 440: Accuracy: 0.8787813130218837\n",
      "Epochs 441: Accuracy: 0.8793479891331523\n",
      "Epochs 442: Accuracy: 0.8788813146885781\n",
      "Epochs 443: Accuracy: 0.879531325522092\n",
      "Epochs 444: Accuracy: 0.8790479841330688\n",
      "Epochs 445: Accuracy: 0.8796813280221337\n",
      "Epochs 446: Accuracy: 0.8791813196886614\n",
      "Epochs 447: Accuracy: 0.8798313305221753\n",
      "Epochs 448: Accuracy: 0.8793146552442541\n",
      "Epochs 449: Accuracy: 0.8799146652444207\n",
      "Epochs 450: Accuracy: 0.8794646577442957\n",
      "Epochs 451: Accuracy: 0.8801646694111569\n",
      "Epochs 452: Accuracy: 0.8795813263554393\n",
      "Epochs 453: Accuracy: 0.8802813380223004\n",
      "Epochs 454: Accuracy: 0.8796313271887864\n",
      "Epochs 455: Accuracy: 0.8804146735778929\n",
      "Epochs 456: Accuracy: 0.8796813280221337\n",
      "Epochs 457: Accuracy: 0.8805646760779346\n",
      "Epochs 458: Accuracy: 0.8797979966332772\n",
      "Epochs 459: Accuracy: 0.8807146785779763\n",
      "Epochs 460: Accuracy: 0.8800813346889115\n",
      "Epochs 461: Accuracy: 0.880864681078018\n",
      "Epochs 462: Accuracy: 0.8802480041334022\n",
      "Epochs 463: Accuracy: 0.881081351355856\n",
      "Epochs 464: Accuracy: 0.8804646744112402\n",
      "Epochs 465: Accuracy: 0.8812480208003467\n",
      "Epochs 466: Accuracy: 0.88064801080018\n",
      "Epochs 467: Accuracy: 0.8813480224670411\n",
      "Epochs 468: Accuracy: 0.8807980133002217\n",
      "Epochs 469: Accuracy: 0.8815313588559809\n",
      "Epochs 470: Accuracy: 0.8809480158002634\n",
      "Epochs 471: Accuracy: 0.8816646944115736\n",
      "Epochs 472: Accuracy: 0.8811146852447541\n",
      "Epochs 473: Accuracy: 0.881781363022717\n",
      "Epochs 474: Accuracy: 0.8811813530225504\n",
      "Epochs 475: Accuracy: 0.8818646977449625\n",
      "Epochs 476: Accuracy: 0.8812980216336939\n",
      "Epochs 477: Accuracy: 0.8819646994116569\n",
      "Epochs 478: Accuracy: 0.8814646910781846\n",
      "Epochs 479: Accuracy: 0.8821980366339439\n",
      "Epochs 480: Accuracy: 0.8816146935782263\n",
      "Epochs 481: Accuracy: 0.8822980383006384\n",
      "Epochs 482: Accuracy: 0.8816813613560226\n",
      "Epochs 483: Accuracy: 0.88244804080068\n",
      "Epochs 484: Accuracy: 0.8818480308005133\n",
      "Epochs 485: Accuracy: 0.8826147102451708\n",
      "Epochs 486: Accuracy: 0.8820313671894532\n",
      "Epochs 487: Accuracy: 0.8827980466341105\n",
      "Epochs 488: Accuracy: 0.8821980366339439\n",
      "Epochs 489: Accuracy: 0.8829647160786013\n",
      "Epochs 490: Accuracy: 0.8823813730228837\n",
      "Epochs 491: Accuracy: 0.8830647177452957\n",
      "Epochs 492: Accuracy: 0.8824813746895782\n",
      "Epochs 493: Accuracy: 0.8832480541342356\n",
      "Epochs 494: Accuracy: 0.8827313788563143\n",
      "Epochs 495: Accuracy: 0.8833980566342773\n",
      "Epochs 496: Accuracy: 0.882881381356356\n",
      "Epochs 497: Accuracy: 0.8834647244120736\n",
      "Epochs 498: Accuracy: 0.8829480491341523\n",
      "Epochs 499: Accuracy: 0.8834813913565226\n",
      "Epochs 500: Accuracy: 0.8830813846897448\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 500, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau 500 epochs, độ chính xác đạt được vào khoảng  88,3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8861886188618862\n"
     ]
    }
   ],
   "source": [
    "def test(X, Y, W1, b1, W2, b2):\n",
    "    Z1, A1, Z2, A2 = foward_propagation(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    print(\"Accuracy: {}\".format(get_accuracy(predictions, Y)))\n",
    "\n",
    "test(X_test, Y_test, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả trên bộ test cũng rơi vào khoảng 88%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
